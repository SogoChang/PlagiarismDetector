{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ddTlUzgvK-Rz",
    "outputId": "12d82a3e-f9ad-4554-e280-98be75713bd3"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/AashitaK/Plagiarism-Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a-QgNzPLUZr",
    "outputId": "24aaffe0-110f-4609-fa38-a052a1aaa7d1"
   },
   "outputs": [],
   "source": [
    "# %cd Plagiarism-Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOJoMM5hLcVK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import os\n",
    "path = \"input/\" # Update path\n",
    "\n",
    "import nltk\n",
    "from nltk import trigrams, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h2tsJHQNLzRA"
   },
   "outputs": [],
   "source": [
    "def clean_file(myfile):\n",
    "    mf = myfile.read()\n",
    "    mf = mf.lower()\n",
    "    mf = re.sub(r'[\\n]\\s*',r' ', mf)\n",
    "    mf = re.sub(r'[\\']|[:]|[+]|\\d+|[--]', '', mf)\n",
    "    mf = re.sub(r'\\(\\)',r'', mf)\n",
    "    mf = re.sub(r'\\.\\s+\\.', r'.', mf)\n",
    "    mf = mf.strip()\n",
    "    return mf\n",
    "\n",
    "def get_dataframe(files):\n",
    "    data = []\n",
    "    for f in files:\n",
    "        with open(path + f, mode='r', encoding='utf-8-sig') as myfile:\n",
    "            myfile = clean_file(myfile)\n",
    "            data.append(myfile)\n",
    "    df = pd.DataFrame(data, columns=['Text'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1nwFHbT6L479",
    "outputId": "7493227d-43b0-47d9-9efc-63231f2a62d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>File_index</th>\n",
       "      <th>Plagiarized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bible studies in the life of paul historical a...</td>\n",
       "      <td>00001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my impatience to inhabit the hermitage not per...</td>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>morning on the beachthe three letters        i...</td>\n",
       "      <td>00003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this morning it rained so hard (though it was ...</td>\n",
       "      <td>00004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deadham hard a romance by lucas malet (mary st...</td>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text File_index  Plagiarized\n",
       "0  bible studies in the life of paul historical a...      00001            1\n",
       "1  my impatience to inhabit the hermitage not per...      00002            1\n",
       "2  morning on the beachthe three letters        i...      00003            1\n",
       "3  this morning it rained so hard (though it was ...      00004            0\n",
       "4  deadham hard a romance by lucas malet (mary st...      00005            1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suspicious_files = sorted([f for f in os.listdir(path) if f.startswith('suspicious-document')])\n",
    "suspicious = get_dataframe(suspicious_files)\n",
    "suspicious['File_index'] = [f[19:24] for f in suspicious_files]\n",
    "plagiarized = pd.read_csv(path + \"Plagiarized.csv\")\n",
    "suspicious['Plagiarized'] = plagiarized.Plagiarized\n",
    "suspicious.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Q3SRrU7EL_M1",
    "outputId": "648b3778-c67d-4358-a2d6-1db504ad842b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>File_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our next day was a pleasant, lazy day, during ...</td>\n",
       "      <td>00018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she stepped back to scyllas side. there was a ...</td>\n",
       "      <td>00040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>punch, or the london charivari. volume . may ,...</td>\n",
       "      <td>00047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the leicestershires beyond baghdad by edward j...</td>\n",
       "      <td>00055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"we soon began to find stones and dirt in the ...</td>\n",
       "      <td>00088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text File_index\n",
       "0  our next day was a pleasant, lazy day, during ...      00018\n",
       "1  she stepped back to scyllas side. there was a ...      00040\n",
       "2  punch, or the london charivari. volume . may ,...      00047\n",
       "3  the leicestershires beyond baghdad by edward j...      00055\n",
       "4  \"we soon began to find stones and dirt in the ...      00088"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_files = sorted([f for f in os.listdir(path) if f.startswith('source-document')])\n",
    "source = get_dataframe(source_files)\n",
    "source['File_index'] = [f[15:20] for f in source_files]\n",
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QuryuWLSMCGA"
   },
   "outputs": [],
   "source": [
    "def process_text(df):\n",
    "    df['Tokens'] = df['Text'].apply(word_tokenize)\n",
    "    punc = (\".\", \",\", \"?\", \"-\", \"!\", \"'\", '\"', \"\\\\\", \"/\", \";\", \"{\", \"}\", \"(\", \")\",\n",
    "            \"[\", \"]\", \"''\", \"``\", \"*\", \"$\", \"%\")\n",
    "    stop = set(stopwords.words('english'))\n",
    "    stop_punc = stop.union(punc)\n",
    "    df.Tokens = df.Tokens.apply(lambda x: [w for w in x if w not in stop_punc])\n",
    "    df['Trigrams'] = df['Tokens'].apply(lambda x: set(trigrams(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "sHlQ47DQMG74",
    "outputId": "9195b19c-59c2-49e3-a21a-f6c67f0eb6cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>File_index</th>\n",
       "      <th>Plagiarized</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bible studies in the life of paul historical a...</td>\n",
       "      <td>00001</td>\n",
       "      <td>1</td>\n",
       "      <td>[bible, studies, life, paul, historical, const...</td>\n",
       "      <td>{(worship, received, given), (christian, breth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my impatience to inhabit the hermitage not per...</td>\n",
       "      <td>00002</td>\n",
       "      <td>1</td>\n",
       "      <td>[impatience, inhabit, hermitage, permitting, w...</td>\n",
       "      <td>{(time, bar, squirmed), (damaged, record, marc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>morning on the beachthe three letters        i...</td>\n",
       "      <td>00003</td>\n",
       "      <td>1</td>\n",
       "      <td>[morning, beachthe, three, letters, iii, old, ...</td>\n",
       "      <td>{(ill, make, ship), (house, behind, cast), (lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this morning it rained so hard (though it was ...</td>\n",
       "      <td>00004</td>\n",
       "      <td>0</td>\n",
       "      <td>[morning, rained, hard, though, fair, yesterda...</td>\n",
       "      <td>{(dined, dinner, comes), (matters, walked, bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deadham hard a romance by lucas malet (mary st...</td>\n",
       "      <td>00005</td>\n",
       "      <td>1</td>\n",
       "      <td>[deadham, hard, romance, lucas, malet, mary, s...</td>\n",
       "      <td>{(entitle, good, title), (history, new, york),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text File_index  Plagiarized  \\\n",
       "0  bible studies in the life of paul historical a...      00001            1   \n",
       "1  my impatience to inhabit the hermitage not per...      00002            1   \n",
       "2  morning on the beachthe three letters        i...      00003            1   \n",
       "3  this morning it rained so hard (though it was ...      00004            0   \n",
       "4  deadham hard a romance by lucas malet (mary st...      00005            1   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [bible, studies, life, paul, historical, const...   \n",
       "1  [impatience, inhabit, hermitage, permitting, w...   \n",
       "2  [morning, beachthe, three, letters, iii, old, ...   \n",
       "3  [morning, rained, hard, though, fair, yesterda...   \n",
       "4  [deadham, hard, romance, lucas, malet, mary, s...   \n",
       "\n",
       "                                            Trigrams  \n",
       "0  {(worship, received, given), (christian, breth...  \n",
       "1  {(time, bar, squirmed), (damaged, record, marc...  \n",
       "2  {(ill, make, ship), (house, behind, cast), (lo...  \n",
       "3  {(dined, dinner, comes), (matters, walked, bac...  \n",
       "4  {(entitle, good, title), (history, new, york),...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suspicious = process_text(suspicious)\n",
    "suspicious.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "v8yG61YBN5Ga",
    "outputId": "c2fc959f-6469-4e6a-f337-e27d96e860ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>File_index</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our next day was a pleasant, lazy day, during ...</td>\n",
       "      <td>00018</td>\n",
       "      <td>[next, day, pleasant, lazy, day, inspected, ka...</td>\n",
       "      <td>{(mud, hut, companions), (party, one, hundred)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>she stepped back to scyllas side. there was a ...</td>\n",
       "      <td>00040</td>\n",
       "      <td>[stepped, back, scyllas, side, deathly, doubt,...</td>\n",
       "      <td>{(brother, safe, herd), (bodies, seem, turn), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>punch, or the london charivari. volume . may ,...</td>\n",
       "      <td>00047</td>\n",
       "      <td>[punch, london, charivari, volume, may, play, ...</td>\n",
       "      <td>{(speaker, rose, cry), (royal, quartpotarium, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the leicestershires beyond baghdad by edward j...</td>\n",
       "      <td>00055</td>\n",
       "      <td>[leicestershires, beyond, baghdad, edward, j.,...</td>\n",
       "      <td>{(english, kept, insisting), (left, front, ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"we soon began to find stones and dirt in the ...</td>\n",
       "      <td>00088</td>\n",
       "      <td>[soon, began, find, stones, dirt, ice, gone, t...</td>\n",
       "      <td>{(crags, within, ship), (stop, train, said), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text File_index  \\\n",
       "0  our next day was a pleasant, lazy day, during ...      00018   \n",
       "1  she stepped back to scyllas side. there was a ...      00040   \n",
       "2  punch, or the london charivari. volume . may ,...      00047   \n",
       "3  the leicestershires beyond baghdad by edward j...      00055   \n",
       "4  \"we soon began to find stones and dirt in the ...      00088   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [next, day, pleasant, lazy, day, inspected, ka...   \n",
       "1  [stepped, back, scyllas, side, deathly, doubt,...   \n",
       "2  [punch, london, charivari, volume, may, play, ...   \n",
       "3  [leicestershires, beyond, baghdad, edward, j.,...   \n",
       "4  [soon, began, find, stones, dirt, ice, gone, t...   \n",
       "\n",
       "                                            Trigrams  \n",
       "0  {(mud, hut, companions), (party, one, hundred)...  \n",
       "1  {(brother, safe, herd), (bodies, seem, turn), ...  \n",
       "2  {(speaker, rose, cry), (royal, quartpotarium, ...  \n",
       "3  {(english, kept, insisting), (left, front, ene...  \n",
       "4  {(crags, within, ship), (stop, train, said), (...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = process_text(source)\n",
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "efPpw7OkOOp5"
   },
   "outputs": [],
   "source": [
    "def Jaccard_similarity_coefficient(A, B):\n",
    "    J = len(A.intersection(B))/len(A.union(B))\n",
    "    return J\n",
    "\n",
    "def containment_measure(A, B):\n",
    "    J = len(A.intersection(B))/len(B)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RtAyQcm8OSrK"
   },
   "outputs": [],
   "source": [
    "def check_plagiarism_Jaccard(doc_trigrams):\n",
    "    Jaccard_similarity_scores = source.Trigrams.apply(lambda s: Jaccard_similarity_coefficient(s, doc_trigrams))\n",
    "    most_similar = Jaccard_similarity_scores.idxmax()\n",
    "    return Jaccard_similarity_scores[most_similar]#, source.loc[most_similar, 'File_index']\n",
    "\n",
    "def check_plagiarism_containment(doc_trigrams):\n",
    "    containment_measure_scores = source.Trigrams.apply(lambda s: containment_measure(s, doc_trigrams))\n",
    "    most_similar = containment_measure_scores.idxmax()\n",
    "    return containment_measure_scores[most_similar]#, source.loc[most_similar, 'File_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3FsGdhQMOVnr"
   },
   "outputs": [],
   "source": [
    "suspicious['Jaccard_similarity_score'] = suspicious.Trigrams.apply(check_plagiarism_Jaccard)\n",
    "suspicious['Containment_measure_score'] = suspicious.Trigrams.apply(check_plagiarism_containment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Zb2QnJTVOYTN",
    "outputId": "5ec4c2bc-9f8b-4a9b-b7d9-6a2d2f21994c"
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"Plagiarized\", y=\"Jaccard_similarity_score\", data=suspicious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "6b675MhDPdvv",
    "outputId": "0d469eee-1686-4d5e-c88c-a900e30372a6"
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"Plagiarized\", y=\"Containment_measure_score\", data=suspicious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "ELyHhWlRPgus",
    "outputId": "3bd23256-0142-45f3-afc6-fc8c2e866c50"
   },
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Jaccard_similarity_score\", y=\"Containment_measure_score\", hue=\"Plagiarized\", data=suspicious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LqsZDCaoPkhJ"
   },
   "outputs": [],
   "source": [
    "def LCS(A, B):\n",
    "    m, n = len(A), len(B)\n",
    "    counter = [[0]*(n+1) for x in range(m+1)]\n",
    "    A, B = list(A), list(B)\n",
    "    longest = 0\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            if A[i] == B[j]:\n",
    "                count = counter[i][j] + 1\n",
    "                counter[i+1][j+1] = count\n",
    "                if count > longest:\n",
    "                    longest = count\n",
    "    return longest\n",
    "\n",
    "def check_plagiarism_LCS(doc):\n",
    "    LCS_scores = source.Tokens.apply(lambda s: LCS(s, doc))\n",
    "    most_similar = LCS_scores.idxmax()\n",
    "    return LCS_scores[most_similar]#, source.loc[most_similar, 'File_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cKWmPuZPndC"
   },
   "outputs": [],
   "source": [
    "suspicious['Longest_common_sequence'] = suspicious.Trigrams.apply(check_plagiarism_LCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJs8iSulPqvN"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "source.Tokens = source.Tokens.apply(lambda x: [lemmatizer.lemmatize(w) for w in x])\n",
    "suspicious.Tokens = suspicious.Tokens.apply(lambda x: [lemmatizer.lemmatize(w) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dABKsFMpPuaa"
   },
   "outputs": [],
   "source": [
    "dummy_function = lambda x: x\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    token_pattern=None,\n",
    "    tokenizer=dummy_function,\n",
    "    preprocessor=dummy_function,\n",
    "    ngram_range=(1, 4),\n",
    "    max_features=1000,\n",
    ")\n",
    "\n",
    "# Concatenate the tokens from both suspicious and source texts\n",
    "combined_tokens = pd.concat([suspicious.Tokens, source.Tokens])\n",
    "\n",
    "# Fit and transform the concatenated tokens\n",
    "DTM = vectorizer.fit_transform(combined_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-o7XgCYMPw3s"
   },
   "outputs": [],
   "source": [
    "LSA = TruncatedSVD(200, algorithm = 'arpack')\n",
    "DTM_LSA = LSA.fit_transform(DTM)\n",
    "DTM_LSA = Normalizer(copy=False).fit_transform(DTM_LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAZj7ElrPxtG"
   },
   "outputs": [],
   "source": [
    "similarity_matrix = np.asarray(np.asmatrix(DTM_LSA) * np.asmatrix(DTM_LSA).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0k_RPhkYP2CZ"
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(similarity_matrix, 0)\n",
    "L = len(suspicious_files)\n",
    "similarity_matrix[:L, :L] = np.zeros((L, L))\n",
    "suspicious['LSA_similarity'] = np.max(similarity_matrix, 1)[:L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "gCgZgahfmWnO",
    "outputId": "a88cbd8a-f71c-45d7-a9f5-1480d7920c7a"
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(x=\"Plagiarized\", y=\"LSA_similarity\", data=suspicious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "9L6eH9iMP3lT",
    "outputId": "7fb8d70a-8390-44d8-aa65-55c4835bcc36"
   },
   "outputs": [],
   "source": [
    "suspicious[['LSA_similarity', 'Jaccard_similarity_score', 'Containment_measure_score', 'Plagiarized']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBPejy2QP8t9",
    "outputId": "e0d753a4-a120-434c-ae5a-a2a4fe20974f"
   },
   "outputs": [],
   "source": [
    "y = suspicious.Plagiarized\n",
    "X = suspicious[['LSA_similarity', 'Jaccard_similarity_score', 'Containment_measure_score']]#, 'Longest_common_sequence']]\n",
    "\n",
    "clf = LogisticRegression()\n",
    "cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kh2jMGLfP-9f",
    "outputId": "e1d2e9b0-fb80-4379-9c46-3c3d76cf5f03"
   },
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(clf, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebfpfVY-P__T",
    "outputId": "a0794a6d-620e-46e9-bc74-3dd70f604118"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "bzKUwfjwQCXe",
    "outputId": "b11c58ff-a7e5-44df-9017-0566403cfa4a"
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
